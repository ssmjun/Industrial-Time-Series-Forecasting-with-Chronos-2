#!/bin/bash

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
BOLD='\033[1m'
NC='\033[0m' # No Color

# í—¤ë” ì¶œë ¥ í•¨ìˆ˜
print_header() {
    echo -e "\n${BLUE}############################################################${NC}"
    echo -e "${YELLOW}ğŸ‘‰ Running Experiment: ${BOLD}$1${NC}"
    echo -e "${BLUE}############################################################${NC}\n"
}

# ==========================================
# ì‹¤í—˜ ì‹œì‘
# ==========================================

# 1. No Covariates, No Cross Learning
print_header "1. No Covariates, No Cross Learning"
python chronos_run.py --use_chronos

# 2. With Covariates, No Cross Learning
print_header "2. With Covariates, No Cross Learning"
python chronos_run.py --use_chronos --use_covariates

# 3. With Covariates, With Cross Learning
print_header "3. With Covariates, With Cross Learning"
python chronos_run.py --use_chronos --use_covariates --use_cross_learning

# 4. Fine-tuning (No Cross Learning)
print_header "4. Fine-tuning - No Cross Learning"
python chronos_run.py --use_chronos --fine_tune --use_covariates \
                    --ft_learning_rate 1e-6 --num_steps 400

# 5. Fine-tuning (With Cross Learning)
print_header "5. Fine-tuning - With Cross Learning"
python chronos_run.py --use_chronos --fine_tune --use_covariates --use_cross_learning

# 6. Continual Pretrained Model
print_header "6. Continual Pretrained Model + Fine-tuning"
python chronos_run.py --use_chronos --use_covariates --continual_pretrain --fine_tune \
                    --ft_learning_rate 1e-6 --num_steps 400 --pretrain_steps 400

# 7. Continual Pretrained Model
print_header "7. Continual Pretrained Model + Fine-tuning + Cross Learning"
python chronos_run.py --use_chronos --use_covariates --continual_pretrain --fine_tune --use_cross_learning

# 8. Continual Pretrained Model + Fine-tuning + Cross Learning + DAS
print_header "8. Continual Pretrained Model + Fine-tuning + Cross Learning + Soft-CL"
python chronos_run.py --use_chronos --use_covariates --continual_pretrain --fine_tune --use_cross_learning --use_das \
                    --ft_learning_rate 5e-6 --pt_learning_rate 5e-6 \
                    --num_steps 400 --pretrain_steps 400

# ì¢…ë£Œ ë©”ì‹œì§€
echo -e "\n${GREEN}${BOLD}âœ… All experiments completed successfully!${NC}\n"
